{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a96472d-c433-4e51-acee-847ec3e2a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b27f057b-192e-4007-bbb5-d7e69c5bc2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'images/train'\n",
    "TEST_DIR = 'images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4766cdf8-099b-4a48-9c84-d9a5716cb3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdataframe(dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in os.listdir(dir):\n",
    "        for imagename in os.listdir(os.path.join(dir,label)):\n",
    "            image_paths.append(os.path.join(dir,label,imagename))\n",
    "            labels.append(label)\n",
    "        print(label, \"completed\")\n",
    "    return image_paths,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b66a040-5fd9-4e6c-ba77-7200fbf1e826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame()\n",
    "train['image'], train['label'] = createdataframe(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ead580a3-3f0b-4f09-84a4-89d0c7552ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                image     label\n",
      "0            images/train\\angry\\0.jpg     angry\n",
      "1            images/train\\angry\\1.jpg     angry\n",
      "2           images/train\\angry\\10.jpg     angry\n",
      "3        images/train\\angry\\10002.jpg     angry\n",
      "4        images/train\\angry\\10016.jpg     angry\n",
      "...                               ...       ...\n",
      "28816  images/train\\surprise\\9969.jpg  surprise\n",
      "28817  images/train\\surprise\\9985.jpg  surprise\n",
      "28818  images/train\\surprise\\9990.jpg  surprise\n",
      "28819  images/train\\surprise\\9992.jpg  surprise\n",
      "28820  images/train\\surprise\\9996.jpg  surprise\n",
      "\n",
      "[28821 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa240481-27b9-4fb2-9a05-ada6d4f5542c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n"
     ]
    }
   ],
   "source": [
    "test = pd.DataFrame()\n",
    "test['image'], test['label'] = createdataframe(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b894d962-710a-4665-bcc8-2a2633dc9559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              image     label\n",
      "0       images/test\\angry\\10052.jpg     angry\n",
      "1       images/test\\angry\\10065.jpg     angry\n",
      "2       images/test\\angry\\10079.jpg     angry\n",
      "3       images/test\\angry\\10095.jpg     angry\n",
      "4       images/test\\angry\\10121.jpg     angry\n",
      "...                             ...       ...\n",
      "7061  images/test\\surprise\\9806.jpg  surprise\n",
      "7062  images/test\\surprise\\9830.jpg  surprise\n",
      "7063  images/test\\surprise\\9853.jpg  surprise\n",
      "7064  images/test\\surprise\\9878.jpg  surprise\n",
      "7065   images/test\\surprise\\993.jpg  surprise\n",
      "\n",
      "[7066 rows x 2 columns]\n",
      "0         images/test\\angry\\10052.jpg\n",
      "1         images/test\\angry\\10065.jpg\n",
      "2         images/test\\angry\\10079.jpg\n",
      "3         images/test\\angry\\10095.jpg\n",
      "4         images/test\\angry\\10121.jpg\n",
      "                    ...              \n",
      "7061    images/test\\surprise\\9806.jpg\n",
      "7062    images/test\\surprise\\9830.jpg\n",
      "7063    images/test\\surprise\\9853.jpg\n",
      "7064    images/test\\surprise\\9878.jpg\n",
      "7065     images/test\\surprise\\993.jpg\n",
      "Name: image, Length: 7066, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(test)\n",
    "print(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e7fd44b-2593-4b09-adc1-49a6cd24e0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d41a587-5dea-45f2-9e82-99be33ff42a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images):\n",
    "    features = []\n",
    "    for image in tqdm(images):\n",
    "        img = load_img(image,grayscale =  True )\n",
    "        img = np.array(img)\n",
    "        features.append(img)\n",
    "    features = np.array(features)\n",
    "    features = features.reshape(len(features),48,48,1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40022ac6-5c83-4a7f-b892-8d2d67cdc1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a090af968242fd8a41a1d785783889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_preprocessing\\image\\utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    }
   ],
   "source": [
    "train_features = extract_features(train['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42f98992-f1fd-4c6a-a2bd-913cce417f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695009b4c0364bc8a13ec792cdf80e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7066 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_features = extract_features(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "030c28bf-4125-4ad0-889a-c0828ee2a64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_features/255.0\n",
    "x_test = test_features/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f518405-fb74-42c5-bf08-15e42b097449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dace65c-b2a7-47bb-b836-1b65d7e71fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "390e946c-6ea0-4cb8-8b06-d835c502ac6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = le.transform(train['label'])\n",
    "y_test = le.transform(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "caf3af0d-c774-4b5f-ba61-b110c6898c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train,num_classes = 7)\n",
    "y_test = to_categorical(y_test,num_classes = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51079657-bcc4-43d7-bb1b-9ddca687dcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# convolutional layers\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "# fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# output layer\n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f018b62a-8d55-4612-9cec-e1a6d2ac1a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = 'accuracy' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44829e78-48eb-4441-b60a-45d03a1df57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "226/226 [==============================] - 257s 1s/step - loss: 1.8242 - accuracy: 0.2434 - val_loss: 1.8054 - val_accuracy: 0.2583\n",
      "Epoch 2/100\n",
      "226/226 [==============================] - 239s 1s/step - loss: 1.7842 - accuracy: 0.2599 - val_loss: 1.7032 - val_accuracy: 0.3087\n",
      "Epoch 3/100\n",
      "226/226 [==============================] - 243s 1s/step - loss: 1.6607 - accuracy: 0.3326 - val_loss: 1.5256 - val_accuracy: 0.4066\n",
      "Epoch 4/100\n",
      "226/226 [==============================] - 242s 1s/step - loss: 1.5385 - accuracy: 0.3984 - val_loss: 1.4101 - val_accuracy: 0.4558\n",
      "Epoch 5/100\n",
      "226/226 [==============================] - 240s 1s/step - loss: 1.4554 - accuracy: 0.4357 - val_loss: 1.3759 - val_accuracy: 0.4706\n",
      "Epoch 6/100\n",
      "226/226 [==============================] - 242s 1s/step - loss: 1.4089 - accuracy: 0.4569 - val_loss: 1.2832 - val_accuracy: 0.5051\n",
      "Epoch 7/100\n",
      "226/226 [==============================] - 255s 1s/step - loss: 1.3706 - accuracy: 0.4739 - val_loss: 1.2511 - val_accuracy: 0.5192\n",
      "Epoch 8/100\n",
      "226/226 [==============================] - 218s 965ms/step - loss: 1.3361 - accuracy: 0.4877 - val_loss: 1.2266 - val_accuracy: 0.5260\n",
      "Epoch 9/100\n",
      "226/226 [==============================] - 221s 980ms/step - loss: 1.3205 - accuracy: 0.4910 - val_loss: 1.2172 - val_accuracy: 0.5401\n",
      "Epoch 10/100\n",
      "226/226 [==============================] - 227s 1s/step - loss: 1.2856 - accuracy: 0.5096 - val_loss: 1.1889 - val_accuracy: 0.5451\n",
      "Epoch 11/100\n",
      "226/226 [==============================] - 224s 991ms/step - loss: 1.2718 - accuracy: 0.5142 - val_loss: 1.1983 - val_accuracy: 0.5423\n",
      "Epoch 12/100\n",
      "226/226 [==============================] - 225s 995ms/step - loss: 1.2547 - accuracy: 0.5196 - val_loss: 1.1806 - val_accuracy: 0.5501\n",
      "Epoch 13/100\n",
      "226/226 [==============================] - 223s 986ms/step - loss: 1.2431 - accuracy: 0.5286 - val_loss: 1.1477 - val_accuracy: 0.5665\n",
      "Epoch 14/100\n",
      "226/226 [==============================] - 224s 990ms/step - loss: 1.2254 - accuracy: 0.5348 - val_loss: 1.1661 - val_accuracy: 0.5580\n",
      "Epoch 15/100\n",
      "226/226 [==============================] - 223s 988ms/step - loss: 1.2120 - accuracy: 0.5393 - val_loss: 1.1283 - val_accuracy: 0.5736\n",
      "Epoch 16/100\n",
      "226/226 [==============================] - 223s 988ms/step - loss: 1.1988 - accuracy: 0.5411 - val_loss: 1.1349 - val_accuracy: 0.5661\n",
      "Epoch 17/100\n",
      "226/226 [==============================] - 221s 979ms/step - loss: 1.1815 - accuracy: 0.5519 - val_loss: 1.1193 - val_accuracy: 0.5783\n",
      "Epoch 18/100\n",
      "226/226 [==============================] - 223s 987ms/step - loss: 1.1733 - accuracy: 0.5530 - val_loss: 1.1295 - val_accuracy: 0.5759\n",
      "Epoch 19/100\n",
      "226/226 [==============================] - 233s 1s/step - loss: 1.1664 - accuracy: 0.5560 - val_loss: 1.1023 - val_accuracy: 0.5873\n",
      "Epoch 20/100\n",
      "226/226 [==============================] - 228s 1s/step - loss: 1.1606 - accuracy: 0.5591 - val_loss: 1.1032 - val_accuracy: 0.5868\n",
      "Epoch 21/100\n",
      "226/226 [==============================] - 227s 1s/step - loss: 1.1397 - accuracy: 0.5651 - val_loss: 1.0881 - val_accuracy: 0.5879\n",
      "Epoch 22/100\n",
      "226/226 [==============================] - 226s 1000ms/step - loss: 1.1286 - accuracy: 0.5704 - val_loss: 1.0807 - val_accuracy: 0.5941\n",
      "Epoch 23/100\n",
      "226/226 [==============================] - 227s 1s/step - loss: 1.1252 - accuracy: 0.5725 - val_loss: 1.0818 - val_accuracy: 0.5967\n",
      "Epoch 24/100\n",
      "226/226 [==============================] - 225s 996ms/step - loss: 1.1140 - accuracy: 0.5760 - val_loss: 1.0975 - val_accuracy: 0.5885\n",
      "Epoch 25/100\n",
      "226/226 [==============================] - 225s 997ms/step - loss: 1.1099 - accuracy: 0.5765 - val_loss: 1.0809 - val_accuracy: 0.5962\n",
      "Epoch 26/100\n",
      "226/226 [==============================] - 226s 998ms/step - loss: 1.0999 - accuracy: 0.5815 - val_loss: 1.0917 - val_accuracy: 0.5873\n",
      "Epoch 27/100\n",
      "226/226 [==============================] - 224s 993ms/step - loss: 1.0948 - accuracy: 0.5864 - val_loss: 1.0827 - val_accuracy: 0.5933\n",
      "Epoch 28/100\n",
      "226/226 [==============================] - 225s 995ms/step - loss: 1.0859 - accuracy: 0.5885 - val_loss: 1.0637 - val_accuracy: 0.6054\n",
      "Epoch 29/100\n",
      "226/226 [==============================] - 226s 998ms/step - loss: 1.0831 - accuracy: 0.5913 - val_loss: 1.0710 - val_accuracy: 0.5999\n",
      "Epoch 30/100\n",
      "226/226 [==============================] - 233s 1s/step - loss: 1.0710 - accuracy: 0.5936 - val_loss: 1.0689 - val_accuracy: 0.6029\n",
      "Epoch 31/100\n",
      "226/226 [==============================] - 240s 1s/step - loss: 1.0683 - accuracy: 0.5958 - val_loss: 1.0711 - val_accuracy: 0.5991\n",
      "Epoch 32/100\n",
      "226/226 [==============================] - 247s 1s/step - loss: 1.0495 - accuracy: 0.6043 - val_loss: 1.0590 - val_accuracy: 0.6026\n",
      "Epoch 33/100\n",
      "226/226 [==============================] - 277s 1s/step - loss: 1.0513 - accuracy: 0.5998 - val_loss: 1.0749 - val_accuracy: 0.6047\n",
      "Epoch 34/100\n",
      "226/226 [==============================] - 272s 1s/step - loss: 1.0446 - accuracy: 0.6048 - val_loss: 1.0562 - val_accuracy: 0.6054\n",
      "Epoch 35/100\n",
      "226/226 [==============================] - 285s 1s/step - loss: 1.0312 - accuracy: 0.6112 - val_loss: 1.0644 - val_accuracy: 0.6039\n",
      "Epoch 36/100\n",
      "226/226 [==============================] - 236s 1s/step - loss: 1.0307 - accuracy: 0.6106 - val_loss: 1.0495 - val_accuracy: 0.6104\n",
      "Epoch 37/100\n",
      "226/226 [==============================] - 232s 1s/step - loss: 1.0213 - accuracy: 0.6135 - val_loss: 1.0524 - val_accuracy: 0.6132\n",
      "Epoch 38/100\n",
      "226/226 [==============================] - 247s 1s/step - loss: 1.0202 - accuracy: 0.6137 - val_loss: 1.0523 - val_accuracy: 0.6104\n",
      "Epoch 39/100\n",
      "226/226 [==============================] - 241s 1s/step - loss: 1.0137 - accuracy: 0.6195 - val_loss: 1.0492 - val_accuracy: 0.6093\n",
      "Epoch 40/100\n",
      "226/226 [==============================] - 236s 1s/step - loss: 1.0077 - accuracy: 0.6208 - val_loss: 1.0519 - val_accuracy: 0.6019\n",
      "Epoch 41/100\n",
      "226/226 [==============================] - 232s 1s/step - loss: 0.9961 - accuracy: 0.6263 - val_loss: 1.0570 - val_accuracy: 0.6114\n",
      "Epoch 42/100\n",
      "226/226 [==============================] - 231s 1s/step - loss: 0.9980 - accuracy: 0.6271 - val_loss: 1.0360 - val_accuracy: 0.6139\n",
      "Epoch 43/100\n",
      "226/226 [==============================] - 236s 1s/step - loss: 0.9918 - accuracy: 0.6290 - val_loss: 1.0447 - val_accuracy: 0.6166\n",
      "Epoch 44/100\n",
      "226/226 [==============================] - 264s 1s/step - loss: 0.9712 - accuracy: 0.6339 - val_loss: 1.0482 - val_accuracy: 0.6104\n",
      "Epoch 45/100\n",
      "226/226 [==============================] - 255s 1s/step - loss: 0.9729 - accuracy: 0.6341 - val_loss: 1.0352 - val_accuracy: 0.6206\n",
      "Epoch 46/100\n",
      "226/226 [==============================] - 248s 1s/step - loss: 0.9709 - accuracy: 0.6361 - val_loss: 1.0515 - val_accuracy: 0.6111\n",
      "Epoch 47/100\n",
      "226/226 [==============================] - 246s 1s/step - loss: 0.9625 - accuracy: 0.6395 - val_loss: 1.0366 - val_accuracy: 0.6216\n",
      "Epoch 48/100\n",
      "226/226 [==============================] - 244s 1s/step - loss: 0.9620 - accuracy: 0.6384 - val_loss: 1.0382 - val_accuracy: 0.6177\n",
      "Epoch 49/100\n",
      "226/226 [==============================] - 244s 1s/step - loss: 0.9479 - accuracy: 0.6421 - val_loss: 1.0408 - val_accuracy: 0.6151\n",
      "Epoch 50/100\n",
      "226/226 [==============================] - 245s 1s/step - loss: 0.9504 - accuracy: 0.6442 - val_loss: 1.0364 - val_accuracy: 0.6193\n",
      "Epoch 51/100\n",
      "174/226 [======================>.......] - ETA: 57s - loss: 0.9400 - accuracy: 0.6457"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x= x_train,y = y_train, batch_size = 128, epochs = 100, validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74cd071a-081c-4fce-9767-1bb0b43bf6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"emotiondetector.json\",'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save(\"emotiondetector.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1ee3ef1-03a3-44d8-a9d4-2b2ba46cac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e95ace48-6db0-442f-be4d-73a2cd44d1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(\"facialemotionmodel.json\", \"r\")\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights(\"facialemotionmodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "768bef01-f262-49a0-bd0b-dbbeb3129710",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['angry','disgust','fear','happy','neutral','sad','surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9648f16e-070e-4a44-99db-0953ce34c2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ef(image):\n",
    "    img = load_img(image,grayscale =  True )\n",
    "    feature = np.array(img)\n",
    "    feature = feature.reshape(1,48,48,1)\n",
    "    return feature/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8199da4-b6fe-4885-936b-b5859349bb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image is of sad\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "model prediction is  sad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_preprocessing\\image\\utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    }
   ],
   "source": [
    "image = 'images/train/sad/42.jpg'\n",
    "print(\"original image is of sad\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b7e4737-391d-44dc-84f0-722ab5b5a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "731d77ed-670e-43ec-ba6b-45a5b2b31846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image is of sad\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "model prediction is  sad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_preprocessing\\image\\utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x186c73dc750>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = 'images/train/sad/42.jpg'\n",
    "print(\"original image is of sad\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)\n",
    "plt.imshow(img.reshape(48,48),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a374c43-89d3-40e1-9051-23e09b92f3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
